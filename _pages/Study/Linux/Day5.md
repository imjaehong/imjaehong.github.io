---
title: "Day5 : ??"
tags:
    - Study
    - Language
date: "2025-06-27"
thumbnail: "/assets/img/thumbnail/Linux_logo.png"
bookmark: true
---

# ğŸ“˜ ì„ í˜• ëª¨ë¸ ìš”ì•½
---

### ğŸ§  1. ì„ í˜• ëª¨ë¸ ê°œìš”
- ì…ë ¥ ë°ì´í„°ë¥¼ ë²¡í„° í˜•íƒœë¡œ ì²˜ë¦¬í•˜ëŠ” ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœì˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸
- ì„ í˜• ë³€í™˜ + ê°„ë‹¨í•œ ê²°ì • í•¨ìˆ˜ë¡œ ë¶„ë¥˜ ìˆ˜í–‰

---

### ğŸ§± 2. ë²¡í„°í™” (Vectorization)
- ì„ í˜• ëª¨ë¸ì€ 1ì°¨ì› ë²¡í„° í˜•íƒœì˜ ì…ë ¥ë§Œ ì²˜ë¦¬ ê°€ëŠ¥
- ë”°ë¼ì„œ, 2D/3D ì´ë¯¸ì§€ë¥¼ 1D ë²¡í„°ë¡œ ë³€í™˜í•´ì•¼ í•¨  
  ì˜ˆ: 4x4 í”½ì…€ ì´ë¯¸ì§€ë¥¼ (1,16) ë²¡í„°ë¡œ ë³€í™˜

---

### ğŸ§® 3. ì„ í˜• ë¶„ë¥˜ê¸° - Score í•¨ìˆ˜
- ì…ë ¥ ë²¡í„°ì™€ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ê° í´ë˜ìŠ¤ì˜ ì ìˆ˜(score) ê³„ì‚°
- Score ê³„ì‚°ì€ í–‰ë ¬ ê³±ì„ í†µí•´ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥

---

### ğŸ“Š 4. Softmax ë¶„ë¥˜ê¸°
- ê° í´ë˜ìŠ¤ì˜ scoreë¥¼ í™•ë¥  ê°’ìœ¼ë¡œ ë³€í™˜
- softmax ì¶œë ¥ì€ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ„

---

### ğŸ“‰ 5. ì†ì‹¤ í•¨ìˆ˜ - Cross Entropy Loss
- ì˜ˆì¸¡ í™•ë¥ ê³¼ ì •ë‹µ í´ë˜ìŠ¤ ê°„ì˜ ê±°ë¦¬ ê³„ì‚°
- ì •ë‹µ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” softmax ê°’ì— `-log`ë¥¼ ì·¨í•´ ì†ì‹¤ ê³„ì‚°

---

### âš™ï¸ 6. ìµœì í™” - SGD (Stochastic Gradient Descent)
- ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— í•™ìŠµí•˜ì§€ ì•Šê³ , ë¯¸ë‹ˆ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²½ì‚¬ í•˜ê°•ë²• ì ìš©
- ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ë¹ ë¥¸ ìˆ˜ë ´ì„ ìœ„í•´ ì‚¬ìš©ë¨

---

### ğŸ§ª 7. ì‹¤ìŠµ ê°œìš” (MNIST)
- MNIST ìˆ«ì ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì„ í˜• ëª¨ë¸ì— ì ìš©í•˜ì—¬ í•™ìŠµ
- ì •í™•ë„ ë° ì†ì‹¤ ê³¡ì„ ì„ ì‹œê°í™”í•˜ì—¬ í•™ìŠµ ê²°ê³¼ ë¶„ì„

---

### âœ… ìš”ì•½
- ì„ í˜• ëª¨ë¸ì€ ê°€ì¥ ê¸°ë³¸ì ì¸ ë¶„ë¥˜ê¸°ì´ë©°, ê¸°ì´ˆ ê°œë…(ë²¡í„°í™”, softmax, cross entropy, SGD ë“±)ì„ í•™ìŠµí•˜ëŠ” ë° ì¤‘ìš”í•¨
- ì´í›„ ì‹ ê²½ë§ ëª¨ë¸ì„ ì´í•´í•˜ê¸° ìœ„í•œ ê¸°ë°˜ ì§€ì‹ì„ ì œê³µí•¨

# ğŸ‘¨â€ğŸ’» ì‹¤ìŠµ
---

### ğŸ’¡ Code : ë²¡í„°í™” ì½”ë“œ
ì´ë¯¸ì§€ë¥¼ ë²¡í„°í™”í•  ë•Œ, numpyë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° flatten ë˜ëŠ” reshapeì„ ì‚¬ìš©í•´ ë²¡í„°í™” í•  ìˆ˜ ìˆë‹¤.

```py
import numpy as np

# random í•¨ìˆ˜ë¡œ 0~255 ì‚¬ì´ì˜ ì„ì˜ì˜ ì •ìˆ˜ë¥¼ ì„±ë¶„ìœ¼ë¡œ ê°–ëŠ” 4x4 í–‰ë ¬ì„ ë§Œë“ ë‹¤.
a = np.random.randint(0, 255, (4, 4))
a
```

```
array([[ 38, 223, 157, 213],
       [104,  79, 231,  31],
       [117,  10,  48,  72],
       [128,  41,   6, 178]])
```       

---

```py
# flattenì„ ì‚¬ìš©í•´ 1ì°¨ì› í–‰ë ¬(ë²¡í„°)ë¡œ ë§Œë“ ë‹¤.
b = a.flatten()
b
```

```
array([ 38, 223, 157, 213, 104,  79, 231,  31, 117,  10,  48,  72, 128,
        41,   6, 178])
```   

---

```py
# reshapeë¥¼ ì‚¬ìš©í•´ í–‰ë ¬ í¬ê¸°ë¥¼ ë°”ê¾¼ë‹¤. -1ì€ ìë™ìœ¼ë¡œ ê³„ì‚°í•œë‹¤ëŠ” ì˜ë¯¸ì´ê³  ì´ ê²½ìš° 16ì„ ì ëŠ” ê²ƒê³¼ ê°™ë‹¤.
# ë§Œì•½ (2, 8)ì˜ í–‰ë ¬ë¡œ ë°”ê¾¸ë ¤ í•œë‹¤ë©´ reshape(2, -1) ë˜ëŠ” reshape(2, 8) ë‘˜ ë‹¤ ê°™ì€ ê²°ê³¼ì´ë‹¤.
c = a.reshape(-1)
c
```

```
array([ 38, 223, 157, 213, 104,  79, 231,  31, 117,  10,  48,  72, 128,
        41,   6, 178])
```   

---

### ğŸ’¡ Code : Mnist ì‹¤ìŠµ

```py
# 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np
import pandas as pd
```

```py
# 2 ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
from tensorflow.keras.datasets.mnist import load_data
(train_x, train_y), (test_x, test_y) = load_data()
```

```py
# 2-1 ë°ì´í„° í™•ì¸í•˜ê¸°
train_x.shape, train_y.shape   # train ë°ì´í„° í¬ê¸° í™•ì¸
test_x.shape, test_y.shape     # test ë°ì´í„° í¬ê¸° í™•ì¸
```

```
((10000, 28, 28), (10000,))
```

```py
# 2-2 ì´ë¯¸ì§€ í™•ì¸í•˜ê¸°
from PIL import Image
img = train_x[0]

import matplotlib.pyplot as plt
img1 = Image.fromarray(img, mode='L')
plt.imshow(img1)

train_y[0]   # ì²«ë²ˆì§¸ ë°ì´í„° í™•ì¸
```

```
np.uint8(5)
```

![alt text](../../../assets/img/Linux/27-1.png)

```py
# 3 ë°ì´í„° ì „ì²˜ë¦¬

# 3-1 ì…ë ¥ í˜•íƒœ ë³€í™˜: 3ì°¨ì› â†’ 2ì°¨ì›
# ë°ì´í„°ë¥¼ 2ì°¨ì› í˜•íƒœë¡œ ë³€í™˜: ì…ë ¥ ë°ì´í„°ê°€ ì„ í˜•ëª¨ë¸ì—ì„œëŠ” ë²¡í„° í˜•íƒœ
train_x1 = train_x.reshape(60000, -1)
test_x1 = test_x.reshape(10000, -1)

# 3-2 ë°ì´í„° ê°’ì˜ í¬ê¸° ì¡°ì ˆ: 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜
train_x2 = train_x1 / 255
test_x2 = test_x1 / 255
```

```py
# 4 ëª¨ë¸ ì„¤ì •

# 4-1 ëª¨ë¸ ì„¤ì •ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 4-2 ëª¨ë¸ ì„¤ì •
md = Sequential()
md.add(Dense(10, activation='softmax', input_shape=(28*28,)))

md.summary()   # ëª¨ë¸ ìš”ì•½
```

```
/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)

Model: "sequential_6"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ dense_6 (Dense)                 â”‚ (None, 10)             â”‚         7,850 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

 Total params: 7,850 (30.66 KB)

 Trainable params: 7,850 (30.66 KB)

 Non-trainable params: 0 (0.00 B)
```

```py
# 5 ëª¨ë¸ í•™ìŠµ ì§„í–‰

# 5-1 ëª¨ë¸ compile: ì†ì‹¤ í•¨ìˆ˜, ìµœì í™” í•¨ìˆ˜, ì¸¡ì • í•¨ìˆ˜ ì„¤ì •
md.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'sgd', metrics = ['acc'])

# 5-2 ëª¨ë¸ í•™ìŠµ: í•™ìŠµ íšŸìˆ˜, batch_size, ê²€ì¦ìš© ë°ì´í„° ì„¤ì •
hist = md.fit(train_x2, train_y, epochs=30, batch_size=64, validation_split=0.2)
```

![alt text](../../../assets/img/Linux/27-1-1.png)

```py
acc = hist.history['acc']
val_acc = hist.history['val_acc']
epoch = np.arange(1, len(acc) + 1)
```

```py
# í•™ìŠµê²°ê³¼ ë¶„ì„ : í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°

plt.figure(figsize=(10,8))
plt.plot(epoch, acc, 'b', label='Training accuracy')
plt.plot(epoch, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
```

![alt text](../../../assets/img/Linux/27-1-2.png)

```py
# 6 í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° í‰ê°€
md.evaluate(test_x2, test_y)

# 7 ê°€ì¤‘ì¹˜ ì €ì¥
weight = md.get_weights()
weight
```

![alt text](../../../assets/img/Linux/27-1-3.png)

```
[array([[-0.01809908,  0.04423299, -0.00407743, ...,  0.06332525,
         -0.00251734,  0.00196751],
        [-0.050407  , -0.05998353, -0.07465094, ..., -0.01433843,
          0.01071206,  0.03646336],
        [ 0.06986522, -0.0116923 , -0.07076468, ...,  0.02445704,
         -0.05563192,  0.0041509 ],
        ...,
        [ 0.03118712, -0.04921252,  0.00195412, ..., -0.00605295,
         -0.00202944,  0.07754893],
        [ 0.08052733, -0.0327304 ,  0.02389491, ...,  0.00695625,
          0.06758214,  0.03055982],
        [-0.05485652,  0.03522244,  0.03506895, ...,  0.00976416,
         -0.06175685,  0.04081956]], dtype=float32),
 array([-0.23029914,  0.30129498,  0.01726046, -0.17140533,  0.06494795,
         0.772551  , -0.05629169,  0.3972938 , -0.94089097, -0.15446219],
       dtype=float32)]
```

```py
# Model Loss ì‹œê°í™”
plt.plot(hist.history['loss'], label='loss')
plt.plot(hist.history['val_loss'], label='val_loss')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
```

![alt text](../../../assets/img/Linux/27-1-4.png)