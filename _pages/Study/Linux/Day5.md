---
title: "Day5 : ??"
tags:
    - Study
    - Language
date: "2025-06-27"
thumbnail: "/assets/img/thumbnail/Linux_logo.png"
bookmark: true
---

# ğŸ§  ë”¥ëŸ¬ë‹ ê°œìš”
---

ë”¥ëŸ¬ë‹ì€ ì¸ê°„ì˜ ë‡Œë¥¼ ëª¨ë°©í•œ **ì¸ê³µì‹ ê²½ë§(ANN)**ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¸°ê³„í•™ìŠµ ê¸°ìˆ ë¡œ, **ë‹¤ì¸µ êµ¬ì¡°ì˜ ì‹ ê²½ë§**ì„ í†µí•´ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.

---

### ğŸ” ì¸ê³µì‹ ê²½ë§(ANN)ì˜ ê°œë…

- **ìƒë¬¼í•™ì  ë‰´ëŸ° êµ¬ì¡°**ì—ì„œ ì°©ì•ˆ.
- ì…ë ¥ â†’ ê°€ì¤‘ì¹˜ â†’ í™œì„±í™” í•¨ìˆ˜ â†’ ì¶œë ¥ íë¦„ìœ¼ë¡œ ë™ì‘.
- ê° ì‹ í˜¸ì˜ ê°•ë„ëŠ” **ê°€ì¤‘ì¹˜(Weight)**ë¡œ í‘œí˜„ë¨.

---

### ğŸ§¬ ë”¥ëŸ¬ë‹(Deep Learning)ì´ë€?

- ì€ë‹‰ì¸µì´ ì—¬ëŸ¬ ê°œì¸ **ì‹¬ì¸µ ì‹ ê²½ë§(Deep Neural Network, DNN)**ì„ í†µí•´ í•™ìŠµí•˜ëŠ” ë°©ì‹.
- **ì‹¬ì¸µ í•™ìŠµ(Deep Learning)**ì´ë¼ê³ ë„ í•¨.

---

### ğŸ› ï¸ ì‹ ê²½ë§ êµ¬ì„± ìš”ì†Œ

| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |
| :--: | :--: |
| ì…ë ¥ì¸µ | í•™ìŠµ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ëŠ” ì¸µ |
| ì€ë‹‰ì¸µ | ê°€ì¤‘í•© ê³„ì‚° ë° ë¹„ì„ í˜• ë³€í™˜ ìˆ˜í–‰ |
| ì¶œë ¥ì¸µ | ìµœì¢… ì˜ˆì¸¡ê°’ì„ ì¶œë ¥ |
| ê°€ì¤‘ì¹˜ | ì…ë ¥ì˜ ì¤‘ìš”ë„ë¥¼ ê²°ì • |
| í¸í–¥ | ê°€ì¤‘í•©ì— ë”í•´ì§€ëŠ” ìƒìˆ˜ë¡œ ì¶œë ¥ ì¡°ì ˆ |

---

### â• ê°€ì¤‘í•© (Weighted Sum)

- ê° ì…ë ¥ê°’ Ã— ê°€ì¤‘ì¹˜ + í¸í–¥  
- ìˆ˜ì‹: **z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b**

---

### âš™ï¸ í™œì„±í™” í•¨ìˆ˜ (Activation Function)

| í•¨ìˆ˜ëª… | íŠ¹ì§• |
| :--: | :--: |
| **Sigmoid** | Sì í˜•íƒœ, ì¶œë ¥ê°’ [0, 1], ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ |
| **Tanh** | ì¶œë ¥ [-1, 1], í‰ê·  0, sigmoidë³´ë‹¤ ìš°ìˆ˜ |
| **ReLU** | 0 ì´í•˜ â†’ 0, 0 ì´ˆê³¼ â†’ ê·¸ëŒ€ë¡œ ì¶œë ¥, ë¹ ë¥¸ í•™ìŠµ |
| **LeakyReLU** | ReLUì˜ ìŒìˆ˜ ì…ë ¥ ë¬´ë°˜ì‘ ë¬¸ì œ í•´ê²° |
| **Softmax** | í™•ë¥  ë¶„í¬ ì¶œë ¥, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ì‚¬ìš© |

---

### ğŸ§­ í•™ìŠµ ê³¼ì • (Training Flow)

1ï¸âƒ£ ìˆœì „íŒŒ (Forward Propagation)
- ì…ë ¥ â†’ ì€ë‹‰ì¸µ â†’ ì¶œë ¥ì¸µìœ¼ë¡œ ì˜ˆì¸¡ê°’ ë„ì¶œ

2ï¸âƒ£ ì†ì‹¤ í•¨ìˆ˜ (Loss Function)
- ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
  - íšŒê·€: MSE
  - ë¶„ë¥˜: Cross Entropy

3ï¸âƒ£ ì˜µí‹°ë§ˆì´ì € (Optimizer)
- ê²½ì‚¬í•˜ê°•ë²• ê¸°ë°˜ìœ¼ë¡œ **ê°€ì¤‘ì¹˜ ìµœì í™”**
- ì „ì²´/ë¯¸ë‹ˆ ë°°ì¹˜ ë°©ì‹ ì‚¬ìš©

4ï¸âƒ£ ì—­ì „íŒŒ (Backpropagation)
- ì˜¤ì°¨ë¥¼ **ì—­ë°©í–¥ ì „íŒŒ**í•´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
- ê° ì¸µì˜ ê°€ì¤‘ì¹˜ì— ëŒ€í•´ **ë¯¸ë¶„ê°’ ê¸°ë°˜ ë³´ì •**

---

### ğŸ§± ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ìœ í˜•

| ìœ í˜• | ì„¤ëª… |
| :--: | :--: |
| **DFN** (ìˆœë°©í–¥ ì‹ ê²½ë§) | ê¸°ë³¸ êµ¬ì¡°, ê³ ì • ì…ë ¥ ì²˜ë¦¬ |
| **RNN** (ìˆœí™˜ ì‹ ê²½ë§) | ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬, ê³¼ê±° ì •ë³´ ë°˜ì˜ |
| **LSTM** | RNN ê°œì„ , ì¥ê¸° ê¸°ì–µ ìœ ì§€ |
| **CNN** | ì´ë¯¸ì§€ ë¶„ì„ íŠ¹í™”, í•©ì„±ê³± ë° í’€ë§ í™œìš© |

---

### ğŸ§  CNNì˜ êµ¬ì¡°

- **í•©ì„±ê³±ì¸µ**: í•„í„°ë¥¼ í†µí•´ íŠ¹ì§• ì¶”ì¶œ
- **í’€ë§ì¸µ**: ë°ì´í„° í¬ê¸° ì¶•ì†Œ, í•µì‹¬ ì •ë³´ ë³´ì¡´
- **ì™„ì „ì—°ê²°ì¸µ**: ìµœì¢… ë¶„ë¥˜ ìˆ˜í–‰

---

### ğŸ”„ ë¹„êµ ìš”ì•½ (DFN vs RNN vs CNN)

| í•­ëª© | DFN | RNN | CNN |
| :--: | :--: | :--: | :--: |
| ì…ë ¥ | ì •ì  | ì‹œê³„ì—´ | ì´ë¯¸ì§€/ì‹œê³„ì—´ |
| íŠ¹ì§• | ë‹¨ë°©í–¥ | ìˆœí™˜ ì—°ê²° | ì§€ì—­ì  íŠ¹ì§• |
| í•™ìŠµ | ì‰¬ì›€ | ì–´ë ¤ì›€ | ì¤‘ê°„ |
| íš¨ìœ¨ | ë‚®ìŒ | ë‚®ìŒ | ë†’ìŒ |

---

### ğŸ’¬ ì›Œë“œ ì„ë² ë”© (Word Embedding)

| ë°©ì‹ | ì„¤ëª… |
| :--: | :--: |
| **One-hot Encoding** | í¬ì†Œ ë²¡í„°, ë‹¨ìˆœ êµ¬ì¡° |
| **Word2Vec** | ì£¼ë³€ ë¬¸ë§¥ â†’ ì¤‘ì‹¬ ë‹¨ì–´ ì˜ˆì¸¡ (CBOW/Skip-gram) |
| **TF-IDF** | ë‹¨ì–´ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ë¶€ì—¬ |
| **FastText** | ë¶€ë¶„ ë‹¨ì–´ ê¸°ë°˜, OOV ë¬¸ì œ í•´ê²° |
| **GloVe** | ë‹¨ì–´ ë™ì‹œ ë“±ì¥ í†µê³„ ê¸°ë°˜ |
| **ELMo** | ë¬¸ë§¥ì— ë”°ë¼ ë²¡í„°ê°€ ë‹¬ë¼ì§€ëŠ” ë™ì  ì„ë² ë”© |

---

### ğŸ¨ ì ëŒ€ì  ìƒì„± ì‹ ê²½ë§ (GAN)

- ë‘ ë„¤íŠ¸ì›Œí¬ê°€ ê²½ìŸ:
  - **Generator**: ì§„ì§œ ê°™ì€ ê°€ì§œ ë°ì´í„° ìƒì„±
  - **Discriminator**: ì§„ì§œì™€ ê°€ì§œ êµ¬ë³„
- ì˜ˆìˆ , ì´ë¯¸ì§€ ìƒì„± ë“±ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥

---

### âœ… ìš”ì•½

- ë”¥ëŸ¬ë‹ì€ **ì¸ê³µì‹ ê²½ë§ì„ í™•ì¥í•œ êµ¬ì¡°**ë¡œ, ë‹¤ì–‘í•œ ë¬¸ì œ í•´ê²°ì— ì ìš© ê°€ëŠ¥
- **í™œì„±í™” í•¨ìˆ˜**, **í•™ìŠµ ì•Œê³ ë¦¬ì¦˜**, **ëª¨ë¸ êµ¬ì¡°**ì— ë”°ë¼ ì„±ëŠ¥ì´ ì¢Œìš°ë¨
- CNN, RNN, GAN, Word Embedding ë“±ì€ ì‹¤ì „ ë¬¸ì œì— ë§ëŠ” ë”¥ëŸ¬ë‹ ê¸°ë²• ì„ íƒì˜ ê¸°ì¤€ì´ ëœë‹¤.

---

# ğŸ› ï¸ ì‘ì—…í•  ë””ë ‰í† ë¦¬ ìƒì„± ë° í™˜ê²½ ì„¤ì •
---

```bash
# 1. ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir F_MNIST                  # ë””ë ‰í† ë¦¬ ì´ë¦„: F_MNIST
cd F_MNIST                     # í•´ë‹¹ ë””ë ‰í† ë¦¬ë¡œ ì´ë™

# 2. ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”
python3 -m venv .fmnist        # ê°€ìƒ í™˜ê²½ ìƒì„± (í´ë” ì´ë¦„: .fmnist)
source .fmnist/bin/activate    # ê°€ìƒ í™˜ê²½ í™œì„±í™”

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -U pip             # pip ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
pip install tensorflow         # TensorFlow (ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬)
pip install matplotlib         # Matplotlib (ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬)
pip install PyQt5              # PyQt5 (Matplotlib GUI ë°±ì—”ë“œìš©)
pip install scikit_learn       # scikit-learn (ë¨¸ì‹ ëŸ¬ë‹ ë° í‰ê°€ ë„êµ¬)

# 4. Qt GUI ë°±ì—”ë“œ ì„¤ì • (Wayland í™˜ê²½ì—ì„œ í•„ìˆ˜)
export QT_QPA_PLATFORM=wayland # Qt GUIë¥¼ Waylandì—ì„œ ì •ìƒ ë™ì‘í•˜ê²Œ ì„¤ì •
```

# ğŸ‘¨â€ğŸ’» ì‹¤ìŠµ
---

### ğŸ’¡ Code : Fashion MNIST

```py
import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib
import matplotlib.pyplot as plt

# dataset load
fashion_mnist = keras.datasets.fashion_mnist

# spilt data (train / test)
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

print(train_images.shape)
print(train_labels.shape)
print(test_images.shape)
print(test_labels.shape)

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
               
matplotlib.use('Qt5Agg')
NUM=20
plt.figure(figsize=(15,15))
plt.subplots_adjust(hspace=1)
for idx in range(NUM):
    sp = plt.subplot(5,5,idx+1)
    plt.imshow(train_images[idx])
    plt.title(f'{class_names[train_labels[idx]]}')
plt.show()

plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

# ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (for ANN)
train_images = train_images / 255.0
test_images = test_images / 255.0

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

plt.figure(figsize=(10,8))
for i in range(20):
    plt.subplot(4,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

model = keras.Sequential ([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax'),
])

model.summary()

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=20)

predictions = model.predict(test_images)

predictions[0]

np.argmax(predictions[0])

test_labels[0]

def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions, test_labels)
plt.show()

from sklearn.metrics import accuracy_score
print('accuracy score : ', accuracy_score(tf.math.argmax(predictions, -1), test_labels))
```
