---
title: "Day6 : CNN"
tags:
    - Study
    - Language
date: "2025-06-30"
thumbnail: "/assets/img/thumbnail/Linux_logo.png"
bookmark: true
---

# ğŸ“Œ CNNë€?
---
??
---

### <í•©ì„±ê³± ì¸µ - Convolution Layer>
- ì ì ˆí•œ í¬ê¸°ì˜ kernel sizeë¥¼ ì°¾ëŠ” ê²Œ ì¤‘ìš”í•¨
- ë³´í†µ 3x3 kernel ì‚¬ìš© â†’ ì‘ì„ìˆ˜ë¡ ë§ì€ feature mapì„ ìŒ“ëŠ” ê²½í–¥ ìˆìŒ
- ë³´í­ strideê°€ 1ì¼ ê²½ìš° í•œ ì¹¸ì”© í•©ì„±ê³± ì—°ì‚° ìˆ˜í–‰
- ì¦‰, kernel í¬ê¸°ê°€ ê°™ì•„ë„ ë³´í­ strideì— ë”°ë¼ feature map í¬ê¸°ëŠ” ë‹¬ë¼ì§
- í•©ì„±ê³± ì¸µì€ í™œì„±í™” í•¨ìˆ˜(ReLU)ë¡œ ë¹„ì„ í˜•ì„±ì„ ë„ì…í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥

### <í’€ë§ ì¸µ - Pooling Layer>
- feature mapì˜ ê³µê°„ì  í¬ê¸°ë¥¼ ì¤„ì„
- ìµœëŒ€í’€ë§ì¸µ: í’€ë§ ìœˆë„ìš° ë‚´ ìµœëŒ€ê°’ ë¦¬í„´
- í‰ê· í’€ë§ì¸µ: í’€ë§ ìœˆë„ìš° ë‚´ í‰ê· ê°’ ë¦¬í„´
- ê³µê°„ ì •ë³´ë¥¼ ìš”ì•½í•˜ì—¬ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ê³  ì£¼ìš” íŠ¹ì§•ì„ ë³´ì¡´

### <ë°€ì§‘ì¸µ - Fully Connected Layer>
- ê°€ì¥ ë§ˆì§€ë§‰ì— flatten ì¸µì„ ë°°ì¹˜í•˜ì—¬ ì§€ì—­ì  íŠ¹ì§•(local feature map)ì„ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
- ë³€í™˜ëœ feature vectorë¥¼ fully_connected layerì— ì…ë ¥í•˜ì—¬ ìµœì¢… ì¶œë ¥ê°’ ê³„ì‚°

### example flow
- ìµœì¢… ì¶œë ¥ê°’ì´ (0.7, 0)ì¸ ê²½ìš° â†’ ì •ë‹µì´ (1, 0)ì´ë¼ë©´ 0.3 ì˜¤ì°¨ ì¡´ì¬ ì´ ì˜¤ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ kernelë“¤ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¡°ì • ê°€ì¤‘ì¹˜ ë³€í™” 
- ì•Œê³ ë¦¬ì¦˜: ì—­ì „íŒŒ(backpropagation), ê²½ì‚¬í•˜ê°•ë²•(gradient descent) ì‚¬ìš©

### CNN ëª¨ë¸ê³¼ ì¸ê°„ì˜ ì‹œê°ì •ë³´ ì²˜ë¦¬ê³¼ì •ì˜ ìœ ì‚¬ì 
- ì¸ê°„ì˜ ì‹œê° ì‹œìŠ¤í…œë„ ì‹œê° í”¼ì§ˆì„ ê±°ì¹˜ë©° ìƒìœ„ ì˜ì—­ìœ¼ë¡œ ì˜¬ë¼ê°ˆìˆ˜ë¡ feature ë³µì¡ë„ê°€ ì¦ê°€í•¨
- CNNì˜ í•©ì„±ê³± ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ë” ë³µì¡í•œ featureë¥¼ ì²˜ë¦¬í•˜ëŠ” êµ¬ì¡°ì™€ ìœ ì‚¬

---

# ğŸ‘¨â€ğŸ’» ì‹¤ìŠµ
---

### ğŸ’¡ Code : CNN Layer êµ¬í˜„

```py
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# í•©ì„±ê³± í•¨ìˆ˜ êµ¬í˜„
def conv(a, b): 
    c = np.array(a) * np.array(b)
    return np.sum(c)

# MaxPooling í•¨ìˆ˜ êµ¬í˜„(í•œ ê°œì˜ map ê³„ì‚°)
def MaxPooling(nimg):  # 2d input
    nimg = np.array(nimg)
    i0, j0 = nimg.shape  # i0 = nimg.shape[0], j0 = nimg.shape[1]
    i1 = int((i0 + 1) / 2)
    j1 = int((j0 + 1) / 2)
    output = np.zeros((i1, j1))

    if i0 % 2 == 1:
        i0 += 1
        tmp = np.zeros((1, j0))
        nimg = np.concatenate([nimg, tmp], axis=0)

    if j0 % 2 == 1:
        j0 += 1
        tmp = np.zeros((i0, 1))
        nimg = np.concatenate([nimg, tmp], axis=1)

    for i in range(output.shape[0]):
        for j in range(output.shape[1]):
            a = np.array(nimg[2*i:2*i+2, 2*j:2*j+2])
            output[i, j] = a.max()
    
    return output

# í•©ì„±ê³± ì¶œë ¥ ì¸µ(reature map) í•¨ìˆ˜ êµ¬í˜„(í•œ ê°œì˜ filter ê³„ì‚°)
def featuring(nimg, filters):
    feature = np.zeros((nimg.shape[0] - 2, nimg.shape[1] - 2))
    for i in range(feature.shape[0]):
        for j in range(feature.shape[1]):
            a = nimg[i:i+3, j:j+3]
            feature[i, j] = conv(a, filters)
    return feature

# MaxPooling ì¶œë ¥ ì¸µ í•¨ìˆ˜ êµ¬í˜„(ì—¬ëŸ¬ map ê³„ì‚°)
def Pooling(nimg):
    nimg = np.array(nimg)
    pool0 = []
    for i in range(len(nimg)):
        pool0.append(MaxPooling(nimg[i]))
    return pool0

# ë°°ì—´ì„ ê·¸ë¦¼ìœ¼ë¡œ ë³€í™˜
def to_img(nimg):
    nimg = np.array(nimg)
    nimg = np.uint8(np.round(nimg))
    fimg = []
    for i in range(len(nimg)):
        fimg.append(Image.fromarray(nimg[i]))
    return fimg

# feature map ìƒì„±(ì—¬ëŸ¬ filter ê³„ì‚°)
def ConvD(nimg, filters):
    nimg = np.array(nimg)
    feat0 = []
    for i in range(len(filters)):
        feat0.append(featuring(nimg, filters[i]))
    return feat0

# ReLU í™œì„±í™” í•¨ìˆ˜
def ReLU(fo):
    fo = np.array(fo)
    fo = (fo > 0) * fo
    return fo

# CNN Layer í•¨ìˆ˜ : Conv + ReLU + MaxPooling
def ConvMax(nimg, filters):
    nimg = np.array(nimg)
    f0 = ConvD(nimg, filters)
    f0 = ReLU(f0)
    fg = Pooling(f0)
    return f0, fg

# ê·¸ë¦¼ ê·¸ë¦¬ê¸° : í•©ì„±ê³± í›„ì˜ ìƒíƒœì™€ MaxPooling í›„ì˜ ìƒíƒœë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë¦¬ê¸°
def draw(f0, fg0, size=(12, 8), k=-1):  # sizeì™€ këŠ” ê¸°ë³¸ê°’ ì„¤ì •
    plt.figure(figsize=size)

    for i in range(len(f0)):
        plt.subplot(2, len(f0), i + 1)
        plt.gca().set_title('Conv' + str(k) + '-' + str(i))
        plt.imshow(f0[i])

    for i in range(len(fg0)):
        plt.subplot(2, len(fg0), len(f0) + i + 1)
        plt.gca().set_title('MaxP' + str(k) + '-' + str(i))
        plt.imshow(fg0[i])

    if k != -1:  # k=-1ì´ ì•„ë‹ˆë©´ ê·¸ë¦¼ì„ ì €ì¥
        plt.savefig('conv' + str(k) + '.png')

# 3ê°œì˜ activation map í•©ì¹˜ê¸° : MaxPooling í›„ì˜ ê²°ê³¼ mapë“¤ì„ í•˜ë‚˜ì˜ ë°ì´í„°ë¡œ í†µí•©
def join(mm):
    mm = np.array(mm)
    m1 = np.zeros((mm.shape[1], mm.shape[2], mm.shape[0]))
    for i in range(mm.shape[1]):
        for j in range(mm.shape[2]):
            for k in range(mm.shape[0]):
                m1[i][j][k] = mm[k][i][j]
    return m1

# CNN Layer ê³¼ì •ì„ ê³„ì‚°í•˜ê³  ê²°ê³¼ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ì¶œë ¥
def ConvDraw(p0, filters, size=(12, 8), k=-1):
    f0, fg0 = ConvMax(p0, filters)
    f0_img = to_img(f0)
    fg1_img = to_img(fg0)
    draw(f0, fg0, size, k)
    p1 = join(fg0)
    return p1

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
nimg31 = np.random.rand(10, 10)
filters = [np.ones((3, 3))] * 3

m0 = ConvDraw(nimg31, filters, (12, 10), 0)
```

### âœ… Result : CNN Layer êµ¬í˜„

![alt text](../../../assets/img/Linux/CNN_Layer.png)

---

# ë¼ë² íŒŒì‹¤ìŠµ
---
sudo apt install rpi-imager : ë¼ì¦ˆë² ë¦¬íŒŒì´ ì´ë¯¸ì§€ ë‹¤ìš´
rpi-imager : ë¼ì¦ˆë² ë¦¬íŒŒì´ ì´ë¯¸ì§€ ì‹¤í–‰
ìš´ì˜ì²´ì œ : RASPBERRY PI OS (64-BIT)
ì €ì¥ì†Œ : Mass Storage Device - 62.5 GB




```py
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10

(train_x, train_y), (test_x, test_y) = cifar10.load_data()

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

train_x = train_x / 255.
test_x = test_x / 255.

from tensorflow.keras.utils import to_categorical

train_y = to_categorical(train_y)
test_y = to_categorical(test_y)

# CNN ëª¨ë¸ ë””ìì¸
from tensorflow.keras import models, layers

model = models.Sequential()

# (32, 32, 3) => (30, 30, 32)
model.add(layers.Conv2D(filters=32, kernel_size=(3, 3),
                        activation='relu',
                        input_shape=(32, 32, 3)))
# (30, 30, 32) => (15, 15, 32)
model.add(layers.MaxPool2D(pool_size=(2, 2)))

# (15, 15, 32) => (13, 13, 64)
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),
                        activation='relu'))

# (13, 13, 64) => (6, 6, 64)
model.add(layers.MaxPool2D(pool_size=(2, 2)))

# (6, 6, 64) => (4, 4, 64)
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),
                        activation='relu'))

# 3Dë¥¼ 1Dë¡œ ë³€í™˜
model.add(layers.Flatten())

# Classification : Fully Connected Layer ì¶”ê°€
model.add(layers.Dense(units=64, activation='relu'))
model.add(layers.Dense(units=10, activation='softmax'))

# ëª¨ë¸ì˜ í•™ìŠµ ì •ë³´ ì„¤ì •
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

# ëª¨ë¸ í•™ìŠµ
history = model.fit(x=train_x, y=train_y, epochs=20, batch_size=256, verbose=2, validation_split=0.2)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_x[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays,
    # which is why you need the extra index
    plt.xlabel(class_names[train_y[i].argmax()])
plt.show()

print(f'í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(train_x)}ì¥')
print(f'í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜: {len(test_x)}ì¥')
print(f'ì´ ë°ì´í„° ìˆ˜: {len(train_x) + len(test_x)}ì¥')

plt.figure(figsize=(15, 15))
for i in range(100):
    plt.subplot(10, 10, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_x[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_y[i].argmax()])
plt.show()

```