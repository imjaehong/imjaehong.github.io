---
title: "Day7 : HARIBO_Mini_Project"
tags:
    - Study
    - Language
date: "2025-07-01"
thumbnail: "/assets/img/thumbnail/Linux_logo.png"
bookmark: true
---

# ğŸš€ Model Improvement Strategy
---
ê¸°ì¡´ CNN ëª¨ë¸ì— ë‹¤ìŒ ì „ëµì„ í†µí•©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ êµ¬ì¡°ë¥¼ êµ¬í˜„í•¨:
1. ë°ì´í„° ì¦ê°• ì ìš©: ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ë³€í˜•ì„ í†µí•´ í•™ìŠµ ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´
2. ì „ì´í•™ìŠµ ë„ì…: MobileNetV2ì˜ ì‚¬ì „í•™ìŠµëœ íŠ¹ì§• ì¶”ì¶œê¸° ì‚¬ìš©
3. Dropout ë° Dense ë ˆì´ì–´ ì¶”ê°€: ì˜¤ë²„í”¼íŒ… ë°©ì§€ ë° ëª¨ë¸ í‘œí˜„ë ¥ í–¥ìƒ
4. EarlyStopping, ModelCheckpoint ì ìš©: ê³¼ì í•© ë°©ì§€ ë° ìµœì  ëª¨ë¸ ì €ì¥
5. ë°ì´í„° ì¦ê°• ê°•í™”: íšŒì „, ì´ë™, í™•ëŒ€/ì¶•ì†Œ, ë°˜ì „ ë“± ë³µí•©ì  ì¦ê°• ì ìš©

---

### ğŸ¬ HARIBO_Dataset Preparation

1. 5ê°€ì§€ í•˜ë¦¬ë³´ ì ¤ë¦¬ ì¢…ë¥˜(bear, cola, egg, heart, ring)ë¥¼ ì§ì ‘ ì´¬ì˜í•˜ì—¬ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ìƒì„±
2. ë‹¤ì–‘í•œ ê°ë„Â·ì¡°ëª…Â·ë°°ê²½ì—ì„œ ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ ì´ 500ì¥ (ê° í´ë˜ìŠ¤ë‹¹ 100ì¥ ë‚´ì™¸)
3. êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œ í›„, Google Colab í™˜ê²½ì—ì„œ ì‹¤ìŠµìš©ìœ¼ë¡œ ì—°ë™

![alt text](../../../assets/img/Linux/haribo_dataset.png)

---

### ğŸ’¡ Code : CNN with Transfer Learning & Augmentation

```py
import matplotlib.pyplot as plt
import numpy as np
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# âœ… êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# âœ… ê²½ë¡œ ì„¤ì •
dataset_path = '/content/drive/MyDrive/haribo_dataset'
model_save_path = '/content/drive/MyDrive/haribo_model.h5'

# âœ… ë°ì´í„° ì¦ê°• ì„¤ì •
datagen = ImageDataGenerator(
    rescale=1./255,              # í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
    validation_split=0.2,        # ì „ì²´ ë°ì´í„° ì¤‘ 20%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©
    rotation_range=90,           # ìµœëŒ€ Â±90ë„ ë²”ìœ„ ë‚´ì—ì„œ ë¬´ì‘ìœ„ íšŒì „
    width_shift_range=0.1,       # ì „ì²´ ë„ˆë¹„ì˜ 10%ë§Œí¼ ì¢Œìš° ì´ë™
    height_shift_range=0.1,      # ì „ì²´ ë†’ì´ì˜ 10%ë§Œí¼ ìƒí•˜ ì´ë™
    shear_range=0.1,             # ì „ë‹¨ ë³€í™˜ (ì´ë¯¸ì§€ë¥¼ ê¸°ìš¸ì´ëŠ” íš¨ê³¼)
    zoom_range=0.1,              # 10% ë²”ìœ„ ë‚´ ë¬´ì‘ìœ„ í™•ëŒ€/ì¶•ì†Œ
    horizontal_flip=True,        # ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë¡œ ë¬´ì‘ìœ„ ë°˜ì „
    fill_mode='nearest'          # ë³€í™˜ í›„ ìƒê¸´ ë¹ˆ ì˜ì—­ì„ ê°€ì¥ ê°€ê¹Œìš´ í”½ì…€ë¡œ ì±„ì›€
)

# âœ… ë°ì´í„° ë¡œë”©
train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(96, 96),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(96, 96),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

# âœ… í´ë˜ìŠ¤ ì´ë¦„ ìë™ ì¶”ì¶œ
class_names = list(train_generator.class_indices.keys())
print("í´ë˜ìŠ¤ ì¸ë±ìŠ¤:", train_generator.class_indices)

# âœ… MobileNetV2 ê¸°ë°˜ ëª¨ë¸ êµ¬ì„±
base_model = MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(len(class_names), activation='softmax')  # í´ë˜ìŠ¤ ìˆ˜ ìë™ ë°˜ì˜
])

model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# âœ… ì½œë°± ì„¤ì •
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)

# âœ… í•™ìŠµ ì‹¤í–‰
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,
    callbacks=[early_stop, checkpoint],
    verbose=2
)

# âœ… ê²°ê³¼ ì‹œê°í™”
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# âœ… í•™ìŠµ ì´ë¯¸ì§€ ì˜ˆì‹œ
x_batch, y_batch = next(train_generator)
plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([]); plt.yticks([]); plt.grid(False)
    plt.imshow(x_batch[i])
    label_idx = np.argmax(y_batch[i])
    plt.xlabel(class_names[label_idx])
plt.tight_layout()
plt.show()

# âœ… ëª¨ë¸ ì €ì¥ (.h5 íŒŒì¼)
model.save(model_save_path)
print(f"ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_save_path}")
```

---

### âœ… Result : í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ë° ì˜ˆì¸¡ í™•ì¸

![alt text](../../../assets/img/Linux/epoch32.png)
![alt text](<../../../assets/img/Linux/validation accuracy.png>)
![alt text](<../../../assets/img/Linux/validation loss.png>)
![alt text](<../../../assets/img/Linux/image ex.png>)

---

### ğŸ” Summary
- MobileNetV2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì „ì´í•™ìŠµ ëª¨ë¸ì´ ì ì€ ë°ì´í„°ì…‹ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
- ì‹¤ì‹œê°„ ì˜ˆì¸¡ í™˜ê²½ì—ë„ ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ë¡œ ì „í™˜ ê°€ëŠ¥ (On-Device AI ì ìš© ê°€ëŠ¥)

---

# ğŸ’» Real-Time Inference Setup on Terminal
---
### ğŸ“ 1. ë””ë ‰í† ë¦¬ êµ¬ì„±

```bash
mkdir haribo_cam_classifier
cd haribo_cam_classifier
```

### ğŸ 2. ê°€ìƒí™˜ê²½ ìƒì„± ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
python3 -m venv venv
source venv/bin/activate

pip install tensorflow opencv-python-headless numpy
```

### ğŸ“¥ 3. í•™ìŠµí•œ ëª¨ë¸(.h5)ì„ Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë³µì‚¬

haribo_model.h5 íŒŒì¼ì„ Google Driveì—ì„œ ë‹¤ìš´ë°›ì•„ `haribo_cam_classifier` ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜ì‹œí‚´

![alt text](../../../assets/img/Linux/h5.png)

### ğŸ§  4. í´ë˜ìŠ¤ ì´ë¦„ íŒŒì¼ ìƒì„± (class_names.json)

```json
["bear", "cola", "egg", "heart", "ring"]
```

### ğŸ’¡ 5. ì‹¤ì‹œê°„ ë¶„ë¥˜ ì½”ë“œ ì‘ì„± (predict_cam.py)

```py
import cv2
import numpy as np
import tensorflow as tf
import json

# ëª¨ë¸ê³¼ í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ
model = tf.keras.models.load_model('haribo_model.h5')

with open('class_names.json', 'r') as f:
    class_names = json.load(f)

def preprocess(frame):
    img = cv2.resize(frame, (96, 96))
    img = img.astype('float32') / 255.0
    return np.expand_dims(img, axis=0)

cap = cv2.VideoCapture(2)
if not cap.isOpened():
    print("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

print("ì ¤ë¦¬ ë¶„ë¥˜ ì‹œì‘! (Q í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ)")
while True:
    ret, frame = cap.read()
    if not ret:
        break

    input_img = preprocess(frame)
    pred = model.predict(input_img)
    label = class_names[np.argmax(pred)]

    # ì˜ˆì¸¡ ê²°ê³¼ í™”ë©´ì— ì¶œë ¥
    cv2.putText(frame, f'Prediction: {label}', (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow('Haribo Classifier', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### 6. OpenCV ì„¤ì¹˜ (GUI ì§€ì› í¬í•¨)

```bash
pip install opencv-python
```

### â–¶ï¸ 7. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰

```bash
python3 predict_cam.py
```

### 8. âœ… ê²°ê³¼ ì •ë¦¬

![alt text](../../../assets/img/Linux/haribo.jpg)

#### ğŸ§ª ì˜ˆì¸¡ ì˜ˆì‹œ: heart

![alt text](../../../assets/img/Linux/heart.png)
![alt text](../../../assets/img/Linux/heart_b.png)

#### ğŸ§ª ì˜ˆì¸¡ ì˜ˆì‹œ: ring
![alt text](../../../assets/img/Linux/ring.png)
![alt text](../../../assets/img/Linux/ring_b.png)

#### ğŸ§ª ì˜ˆì¸¡ ì˜ˆì‹œ: cola
![alt text](../../../assets/img/Linux/cola.png)
![alt text](../../../assets/img/Linux/cola_b.png)

#### ğŸ§ª ì˜ˆì¸¡ ì˜ˆì‹œ: egg

![alt text](../../../assets/img/Linux/egg.png)
![alt text](../../../assets/img/Linux/egg_b.png)

#### ğŸ§ª ì˜ˆì¸¡ ì˜ˆì‹œ: bear

![alt text](../../../assets/img/Linux/bear.png)
![alt text](../../../assets/img/Linux/bear_b.png)
