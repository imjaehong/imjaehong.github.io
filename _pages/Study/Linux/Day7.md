---
title: "Day7 : HARIBO_Mini_Project"
tags:
    - Study
    - Language
date: "2025-07-01"
thumbnail: "/assets/img/thumbnail/Linux_logo.png"
bookmark: true
---

# Model Improvement Strategy
---
ê¸°ì¡´ CNN ëª¨ë¸ì— ë‹¤ìŒ ì „ëµì„ í†µí•©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ êµ¬ì¡°ë¥¼ êµ¬í˜„í•¨:

1. ë°ì´í„° ì¦ê°• ì ìš©: ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ë³€í˜•ì„ í†µí•´ í•™ìŠµ ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´
2. ì „ì´í•™ìŠµ ë„ì…: MobileNetV2ì˜ ì‚¬ì „í•™ìŠµëœ íŠ¹ì§• ì¶”ì¶œê¸° ì‚¬ìš©
3. Dropout ë° Dense ë ˆì´ì–´ ì¶”ê°€: ì˜¤ë²„í”¼íŒ… ë°©ì§€ ë° ëª¨ë¸ í‘œí˜„ë ¥ í–¥ìƒ
4. EarlyStopping, ModelCheckpoint ì ìš©: ê³¼ì í•© ë°©ì§€ ë° ìµœì  ëª¨ë¸ ì €ì¥
5. ë°ì´í„° ì¦ê°• ê°•í™”: íšŒì „, ì´ë™, í™•ëŒ€/ì¶•ì†Œ, ë°˜ì „ ë“± ë³µí•©ì  ì¦ê°• ì ìš©

---

### ğŸ’¡ Code : CNN with Transfer Learning & Augmentation

```py
import matplotlib.pyplot as plt
import numpy as np
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# âœ… êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# âœ… ê²½ë¡œ ì„¤ì •
dataset_path = '/content/drive/MyDrive/haribo_dataset'
model_save_path = '/content/drive/MyDrive/haribo_model.h5'

# âœ… ë°ì´í„° ì¦ê°• ì„¤ì •
datagen = ImageDataGenerator(
    rescale=1./255,              # í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
    validation_split=0.2,        # ì „ì²´ ë°ì´í„° ì¤‘ 20%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©
    rotation_range=90,           # ìµœëŒ€ Â±90ë„ ë²”ìœ„ ë‚´ì—ì„œ ë¬´ì‘ìœ„ íšŒì „
    width_shift_range=0.1,       # ì „ì²´ ë„ˆë¹„ì˜ 10%ë§Œí¼ ì¢Œìš° ì´ë™
    height_shift_range=0.1,      # ì „ì²´ ë†’ì´ì˜ 10%ë§Œí¼ ìƒí•˜ ì´ë™
    shear_range=0.1,             # ì „ë‹¨ ë³€í™˜ (ì´ë¯¸ì§€ë¥¼ ê¸°ìš¸ì´ëŠ” íš¨ê³¼)
    zoom_range=0.1,              # 10% ë²”ìœ„ ë‚´ ë¬´ì‘ìœ„ í™•ëŒ€/ì¶•ì†Œ
    horizontal_flip=True,        # ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë¡œ ë¬´ì‘ìœ„ ë°˜ì „
    fill_mode='nearest'          # ë³€í™˜ í›„ ìƒê¸´ ë¹ˆ ì˜ì—­ì„ ê°€ì¥ ê°€ê¹Œìš´ í”½ì…€ë¡œ ì±„ì›€
)

# âœ… ë°ì´í„° ë¡œë”©
train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(96, 96),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(96, 96),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

# âœ… í´ë˜ìŠ¤ ì´ë¦„ ìë™ ì¶”ì¶œ
class_names = list(train_generator.class_indices.keys())
print("í´ë˜ìŠ¤ ì¸ë±ìŠ¤:", train_generator.class_indices)

# âœ… MobileNetV2 ê¸°ë°˜ ëª¨ë¸ êµ¬ì„±
base_model = MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(len(class_names), activation='softmax')  # í´ë˜ìŠ¤ ìˆ˜ ìë™ ë°˜ì˜
])

model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# âœ… ì½œë°± ì„¤ì •
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)

# âœ… í•™ìŠµ ì‹¤í–‰
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,
    callbacks=[early_stop, checkpoint],
    verbose=2
)

# âœ… ê²°ê³¼ ì‹œê°í™”
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# âœ… í•™ìŠµ ì´ë¯¸ì§€ ì˜ˆì‹œ
x_batch, y_batch = next(train_generator)
plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([]); plt.yticks([]); plt.grid(False)
    plt.imshow(x_batch[i])
    label_idx = np.argmax(y_batch[i])
    plt.xlabel(class_names[label_idx])
plt.tight_layout()
plt.show()

# âœ… ëª¨ë¸ ì €ì¥ (.h5 íŒŒì¼)
model.save(model_save_path)
print(f"ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_save_path}")
```

### âœ… Result : í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ë° ì˜ˆì¸¡ í™•ì¸

![alt text](../../../assets/img/Linux/epoch32.png)
![alt text](<../../../assets/img/Linux/validation accuracy.png>)
![alt text](<../../../assets/img/Linux/validation loss.png>)
![alt text](<../../../assets/img/Linux/image ex.png>)

### ğŸ” Summary
- MobileNetV2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì „ì´í•™ìŠµ ëª¨ë¸ì´ ì ì€ ë°ì´í„°ì…‹ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
- ì‹¤ì‹œê°„ ì˜ˆì¸¡ í™˜ê²½ì—ë„ ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°ë¡œ ì „í™˜ ê°€ëŠ¥ (On-Device AI ì ìš© ê°€ëŠ¥)

# í„°ë¯¸ë„ ì‘ì—… ì ì–´ì•¼ë¨
































# ê²°ê³¼

![alt text](../../../assets/img/Linux/haribo.jpg)
![alt text](../../../assets/img/Linux/heart.png)
![alt text](../../../assets/img/Linux/heart_b.png)
![alt text](../../../assets/img/Linux/ring.png)
![alt text](../../../assets/img/Linux/ring_b.png)
![alt text](../../../assets/img/Linux/cola.png)
![alt text](../../../assets/img/Linux/cola_b.png)
![alt text](../../../assets/img/Linux/egg.png)
![alt text](../../../assets/img/Linux/egg_b.png)
![alt text](../../../assets/img/Linux/bear.png)
![alt text](../../../assets/img/Linux/bear_b.png)
